{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2Ye40DgGzum",
    "outputId": "1c46a17f-9a4b-47d5-abc4-aea803a49951"
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install customtkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jwtb0eLVRc3v"
   },
   "outputs": [],
   "source": [
    "from customtkinter import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGvlSx1UG3HT",
    "outputId": "c7d85fac-29db-40e4-847d-0d8d41d46550",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\RITIK\n",
      "[nltk_data]     NAYAK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\RITIK\n",
      "[nltk_data]     NAYAK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ROxpB_PZRc3v"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlD4-zJSKdnw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C0lmlE4GKanX"
   },
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OpGcHBaIKWkq"
   },
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2KzUGD-ZKTEy"
   },
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9N11Rw02KQHn"
   },
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7XLf0dsPKM6R"
   },
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TQIemmWZKL7k"
   },
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Hm7ANDZWKDy3"
   },
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))*0.8\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ByVgiyAWJ-MS"
   },
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWn0uBI9SNcv",
    "outputId": "5d19392a-6bc2-4a1f-dc08-f41da3fe05e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YMw1eJKFctp",
    "outputId": "76091089-fa0f-48ec-dee8-f5ad5a9b3caa"
   },
   "outputs": [],
   "source": [
    "def summ(input_string):\n",
    "    sentences = sent_tokenize(input_string) # NLTK function\n",
    "    total_documents = len(sentences)\n",
    "    '''\n",
    "    We already have a sentence tokenizer, so we just need\n",
    "    to run the sent_tokenize() method to create the array of sentences.\n",
    "    '''\n",
    "    # 1 Sentence Tokenize\n",
    "    sentences = sent_tokenize(input_string)\n",
    "    total_documents = len(sentences)\n",
    "    \n",
    "    # 2 Create the Frequency matrix of the words in each sentence.\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "    '''\n",
    "    # 3 Calculate TermFrequency and generate a matrix\n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    \n",
    "    \n",
    "    # 4 creating table for documents per words\n",
    "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "    '''\n",
    "    # 5 Calculate IDF and generate a matrix\n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "    \n",
    "    \n",
    "    # 6 Calculate TF-IDF and generate a matrix\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    \n",
    "    \n",
    "    # 7 Important Algorithm: score the sentences\n",
    "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "    \n",
    "    \n",
    "    # 8 Find the threshold\n",
    "    threshold = _find_average_score(sentence_scores)\n",
    "    \n",
    "    \n",
    "    # 9 Important Algorithm: Generate the summary\n",
    "    summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "\n",
    "    # print(sentences)\n",
    "    # print(freq_matrix)\n",
    "    # print(tf_matrix)\n",
    "    # print(idf_matrix)\n",
    "    # print(tf_idf_matrix)\n",
    "    # print(sentence_scores)\n",
    "    # print(summary)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeN_OFMqSK-i",
    "outputId": "98880291-c797-478c-fbd0-3ce379b1579a"
   },
   "outputs": [],
   "source": [
    "def process_input():\n",
    "    input_text = text_box1.get(\"1.0\", \"end\") \n",
    "    processed_text = summ(input_text)  \n",
    "    text_box2.delete(\"1.0\", \"end\")  \n",
    "    text_box2.insert(\"1.0\", processed_text)\n",
    "    \n",
    "    # Create and generate the word cloud\n",
    "    wordcloud = WordCloud().generate(input_text)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(wordcloud, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Word Cloud Visualization\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"The Middle East is on the brink of a devastating full-scale conflict as Iran and Israel engage in a dangerous game of retaliation. On Saturday, April 13, Iran launched a massive drone and missile attack on Israel, following an Israeli strike on its embassy compound in Syria. Iranian Foreign Minister Hossein Amirabdollahian claimed that Iran gave neighbouring countries and Israel's ally, the United States, 72 hours' notice before the attack. However, a senior official in US President Joe Biden's administration denied this, stating that Washington did not receive any such warning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summ(\"The Middle East is on the brink of a devastating full-scale conflict as Iran and Israel engage in a dangerous game of retaliation. On Saturday, April 13, Iran launched a massive drone and missile attack on Israel, following an Israeli strike on its embassy compound in Syria. Iranian Foreign Minister Hossein Amirabdollahian claimed that Iran gave neighbouring countries and Israel's ally, the United States, 72 hours' notice before the attack. However, a senior official in US President Joe Biden's administration denied this, stating that Washington did not receive any such warning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = CTk()\n",
    "app.geometry(\"600x650\")\n",
    "app.resizable(0,0)\n",
    "\n",
    "side_img_data = Image.open(\"side-img.png\")\n",
    "txt_icon_data = Image.open(\"email-icon.png\")\n",
    "\n",
    "side_img = CTkImage(dark_image=side_img_data, light_image=side_img_data, size=(150, 650))\n",
    "txt_icon = CTkImage(dark_image=txt_icon_data, light_image=txt_icon_data, size=(20,20))\n",
    "\n",
    "CTkLabel(master=app, text=\"\", image=side_img).pack(expand=True, side=\"left\")\n",
    "\n",
    "frame = CTkFrame(master=app, width=480, height=650, fg_color=\"#ffffff\")\n",
    "frame.pack_propagate(0)\n",
    "frame.pack(expand=True, side=\"right\")\n",
    "\n",
    "CTkLabel(master=frame, text=\"Welcome To Text Summarizer!\", text_color=\"#601E88\", anchor=\"w\", justify=\"left\", font=(\"Arial Bold\", 24)).pack(anchor=\"w\", pady=(50, 5), padx=(25, 0))\n",
    "CTkLabel(master=frame, text=\"Created by Ritik Nayak\", text_color=\"#7E7E7E\", anchor=\"w\", justify=\"left\", font=(\"Arial Bold\", 12)).pack(anchor=\"w\", padx=(25, 0))\n",
    "\n",
    "CTkLabel(master=frame, text=\"  Text:\", text_color=\"#601E88\", anchor=\"w\", justify=\"left\", font=(\"Arial Bold\", 14), image=txt_icon, compound=\"left\").pack(anchor=\"w\", pady=(38, 0), padx=(25, 0))\n",
    "text_box1 = CTkTextbox(master=frame, width=400, height=200, fg_color=\"#EEEEEE\", border_color=\"#601E88\", border_width=1, text_color=\"#000000\")\n",
    "text_box1.pack(anchor=\"w\", padx=(25, 0))\n",
    "\n",
    "CTkLabel(master=frame, text=\"  Summary:\", text_color=\"#601E88\", anchor=\"w\", justify=\"left\", font=(\"Arial Bold\", 14), compound=\"left\").pack(anchor=\"w\", pady=(21, 0), padx=(25, 0))\n",
    "text_box2 = CTkTextbox(master=frame, width=400, height=100, fg_color=\"#EEEEEE\", border_color=\"#601E88\", border_width=1, text_color=\"#000000\")\n",
    "text_box2.pack(anchor=\"w\", padx=(25, 0))\n",
    "\n",
    "CTkButton(master=frame, text=\"click here!\", fg_color=\"#601E88\", hover_color=\"#E44982\", font=(\"Arial Bold\", 12), text_color=\"#ffffff\", width=225, command = process_input).pack(anchor=\"center\", pady=(40, 0), padx=(25, 0))\n",
    "\n",
    "\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibNMMrgWSRLg",
    "outputId": "3fd7d7db-2727-4318-b20d-a0fadb154821"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49XBfRh4STJl",
    "outputId": "7e4c61bb-3075-4fc4-c34c-ad73a4d3d3e4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
